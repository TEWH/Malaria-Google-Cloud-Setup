{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tHgD_Crwdgjd"
   },
   "outputs": [],
   "source": [
    "# IMPORT RELEVANT PACKAGES AND LIBRARIES\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VZIOeMMR-ho5"
   },
   "outputs": [],
   "source": [
    "# Download zip file with images if not already exists\n",
    "!wget -nc ftp://lhcftp.nlm.nih.gov/Open-Access-Datasets/Malaria/cell_images.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dlZCOkJU-hOi"
   },
   "outputs": [],
   "source": [
    "# Randomly generate test/train set\n",
    "import os\n",
    "import random\n",
    "from shutil import copyfile\n",
    "from zipfile import ZipFile\n",
    "\n",
    "# Set \"True\" to re-randomize image set on every run\n",
    "REGENERATE_IMAGES_EVERY_RUN = True\n",
    "\n",
    "if REGENERATE_IMAGES_EVERY_RUN:\n",
    "    !rm -r Malaria_Dataset/\n",
    "\n",
    "ROOT_DIR = os.getcwd()\n",
    "CELL_IMAGES_DIR = os.path.join(ROOT_DIR, \"cell_images\")\n",
    "PARASITIZED_DIR = os.path.join(CELL_IMAGES_DIR, \"Parasitized\")\n",
    "UNINFECTED_DIR = os.path.join(CELL_IMAGES_DIR, \"Uninfected\")\n",
    "MALARIA_DATASET_DIR = os.path.join(ROOT_DIR, \"Malaria_Dataset\")\n",
    "TRAINING_SET_DIR = os.path.join(MALARIA_DATASET_DIR, \"Training_Set\")\n",
    "TRAIN_PARASITIZED_DIR = os.path.join(TRAINING_SET_DIR, \"Parasitized\")\n",
    "TRAIN_UNINFECTED_DIR = os.path.join(TRAINING_SET_DIR, \"Uninfected\")\n",
    "TESTING_SET_DIR = os.path.join(MALARIA_DATASET_DIR, \"Testing_Set\")\n",
    "TEST_PARASITIZED_DIR = os.path.join(TESTING_SET_DIR, \"Parasitized\")\n",
    "TEST_UNINFECTED_DIR = os.path.join(TESTING_SET_DIR, \"Uninfected\")\n",
    "\n",
    "# Ignore script if test/train set already exists\n",
    "if os.path.isdir(MALARIA_DATASET_DIR):\n",
    "    raise SystemExit(\"test/train set already exists!\")\n",
    "\n",
    "# Extract images if not already extracted\n",
    "if not os.path.isdir(\"cell_images\"):\n",
    "    print(\"Extracting images...\")\n",
    "\n",
    "    with ZipFile(os.path.join(ROOT_DIR, \"cell_images.zip\"), \"r\") as zipObj:\n",
    "        zipObj.extractall()\n",
    "\n",
    "cell_images = os.listdir(CELL_IMAGES_DIR)\n",
    "parasitized_images = os.listdir(PARASITIZED_DIR)\n",
    "uninfected_images = os.listdir(UNINFECTED_DIR)\n",
    "train_test_ratio = 0.8\n",
    "target_parasitized_train_size = int(len(parasitized_images) * train_test_ratio)\n",
    "target_uninfected_train_size = int(len(uninfected_images) * train_test_ratio)\n",
    "\n",
    "# Randomly move 20% of parisitized images to testing set\n",
    "print(\"Copying parisitized images to testing set...\")\n",
    "os.makedirs(TEST_PARASITIZED_DIR, exist_ok=True)\n",
    "\n",
    "while len(parasitized_images) > target_parasitized_train_size:\n",
    "    cell_image = random.choice(parasitized_images)\n",
    "    cell_image_dir = os.path.join(PARASITIZED_DIR, cell_image)\n",
    "    renamed_dir = os.path.join(TEST_PARASITIZED_DIR, cell_image)\n",
    "\n",
    "    copyfile(cell_image_dir, renamed_dir)\n",
    "    parasitized_images.remove(cell_image)\n",
    "\n",
    "# Move the remaining parisitized images to training set\n",
    "print(\"Copying parisitized images to training set...\")\n",
    "os.makedirs(TRAIN_PARASITIZED_DIR, exist_ok=True)\n",
    "\n",
    "while len(parasitized_images) > 0:\n",
    "    cell_image = random.choice(parasitized_images)\n",
    "    cell_image_dir = os.path.join(PARASITIZED_DIR, cell_image)\n",
    "    renamed_dir = os.path.join(TRAIN_PARASITIZED_DIR, cell_image)\n",
    "\n",
    "    copyfile(cell_image_dir, renamed_dir)\n",
    "    parasitized_images.remove(cell_image)\n",
    "\n",
    "# Randomly move 20% of uninfected images to testing set\n",
    "print(\"Copying uninfected images to testing set...\")\n",
    "os.makedirs(TEST_UNINFECTED_DIR, exist_ok=True)\n",
    "\n",
    "while len(uninfected_images) > target_uninfected_train_size:\n",
    "    cell_image = random.choice(uninfected_images)\n",
    "    cell_image_dir = os.path.join(UNINFECTED_DIR, cell_image)\n",
    "    renamed_dir = os.path.join(TEST_UNINFECTED_DIR, cell_image)\n",
    "\n",
    "    copyfile(cell_image_dir, renamed_dir)\n",
    "    uninfected_images.remove(cell_image)\n",
    "\n",
    "# Move the remaining uninfected images to training set\n",
    "print(\"Copying uninfected images to training set...\")\n",
    "os.makedirs(TRAIN_UNINFECTED_DIR, exist_ok=True)\n",
    "\n",
    "while len(uninfected_images) > 0:\n",
    "    cell_image = random.choice(uninfected_images)\n",
    "    cell_image_dir = os.path.join(UNINFECTED_DIR, cell_image)\n",
    "    renamed_dir = os.path.join(TRAIN_UNINFECTED_DIR, cell_image)\n",
    "\n",
    "    copyfile(cell_image_dir, renamed_dir)\n",
    "    uninfected_images.remove(cell_image)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5uhGSmd4Akjz"
   },
   "outputs": [],
   "source": [
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model \n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras import backend as k \n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "\n",
    "# INITIALIZE VARAIBLES\n",
    "train_size = len(os.listdir(TRAIN_PARASITIZED_DIR) + os.listdir(TRAIN_UNINFECTED_DIR))\n",
    "test_size = len(os.listdir(TEST_PARASITIZED_DIR) + os.listdir(TEST_UNINFECTED_DIR))\n",
    "img_width, img_height = 128, 128                         # images should be rescaled to 128x128 pixels\n",
    "train_data_dir = TRAINING_SET_DIR                        # directory of training set folder\n",
    "validation_data_dir = TESTING_SET_DIR                    # directory of test set folder\n",
    "nb_train_samples = train_size                            # number of images in training set\n",
    "nb_validation_samples = test_size                        # number of images in testing set\n",
    "epochs = 10                                              # number of epochs to go through\n",
    "batch_size = 10                                          # number of batches (weights updated after each batch)\n",
    "\n",
    "base_model = applications.VGG19(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 3))\n",
    "\n",
    "# Freeze the layers which you don't want to train. Here I am freezing the first 5 layers.\n",
    "#for layer in base_model.layers[:10]:\n",
    "#    layer.trainable = False\n",
    "\n",
    "#Adding custom Layers \n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(512, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(512, activation=\"relu\")(x)\n",
    "predictions = Dense(2, activation=\"softmax\")(x)\n",
    "\n",
    "# creating the final model \n",
    "model = Model(input = base_model.input, output = predictions)\n",
    "\n",
    "# compile the model \n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.00001, momentum=0.9), metrics=[\"accuracy\"])\n",
    "\n",
    "# output model architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MWNqyYm8eHwl"
   },
   "outputs": [],
   "source": [
    "# GENERATE IMAGES AND TRAIN MODEL\n",
    "#   Here, we generate variants of our original dataset. Examples of variants \n",
    "#   include images that are flipped, rotated, rescaled in size, and sheared.\n",
    "#   The purpose of this is to prevent overfitting of the model. It can also \n",
    "#   better help generalize the identification of different objects. For example,\n",
    "#   this way, the model can identify a red blood cell that is oriented differently.\n",
    "\n",
    "# build training image generator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    rotation_range = 20,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True)\n",
    "    #shear_range=0.2,\n",
    "    #zoom_range=0.1,\n",
    "\n",
    "\n",
    "# build testing image generator\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "# generate training images\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "# generate testing images\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "# fit the model on the generated images\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples)\n",
    "    #class_weight = class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pTNMBYHgrfQ_"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "OliverZhao_VGG19_No_Upload",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
